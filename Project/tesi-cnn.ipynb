{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import zipfile\nimport os\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import optimizers\nfrom keras import layers\nfrom keras.regularizers import l1\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, concatenate\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils.vis_utils import plot_model\nimport pylab as pl\nimport numpy as np\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing\nimport math\n\n\n# audio lib\nimport librosa\nimport librosa.display\nfrom librosa.util import fix_length\n\nimport IPython.display as ipd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-28T18:59:44.864419Z","iopub.execute_input":"2022-04-28T18:59:44.865087Z","iopub.status.idle":"2022-04-28T18:59:53.997858Z","shell.execute_reply.started":"2022-04-28T18:59:44.864980Z","shell.execute_reply":"2022-04-28T18:59:53.996705Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:53.999685Z","iopub.execute_input":"2022-04-28T18:59:53.999927Z","iopub.status.idle":"2022-04-28T18:59:54.004133Z","shell.execute_reply.started":"2022-04-28T18:59:53.999896Z","shell.execute_reply":"2022-04-28T18:59:54.003589Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = '../input/PMEmo2019'\nchorus_path = '../input/PMEmo2019/chorus'","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.005060Z","iopub.execute_input":"2022-04-28T18:59:54.005553Z","iopub.status.idle":"2022-04-28T18:59:54.030080Z","shell.execute_reply.started":"2022-04-28T18:59:54.005514Z","shell.execute_reply":"2022-04-28T18:59:54.029376Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"annotations = pd.read_csv(path + '/annotations/static_annotations.csv')\nannotations['musicId'] = annotations['musicId'].astype(str)\nannotations.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.031966Z","iopub.execute_input":"2022-04-28T18:59:54.032222Z","iopub.status.idle":"2022-04-28T18:59:54.072515Z","shell.execute_reply.started":"2022-04-28T18:59:54.032192Z","shell.execute_reply":"2022-04-28T18:59:54.071890Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"annotations.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.073606Z","iopub.execute_input":"2022-04-28T18:59:54.073934Z","iopub.status.idle":"2022-04-28T18:59:54.089455Z","shell.execute_reply.started":"2022-04-28T18:59:54.073906Z","shell.execute_reply":"2022-04-28T18:59:54.088873Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"labels = []\n\nfor index, row in annotations.iterrows():\n    if row[1] <= 0.5 and row[2] <= 0.5:\n        labels.append(0) #LL\n    elif  row[1] <= 0.5 and row[2] > 0.5:\n            labels.append(1) #LW\n    elif  row[1] > 0.5 and row[2] <= 0.5:\n            labels.append(2) #HL\n    elif  row[1] > 0.5 and row[2] > 0.5:\n            labels.append(3) #HH\n            \nlen(labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.090506Z","iopub.execute_input":"2022-04-28T18:59:54.090862Z","iopub.status.idle":"2022-04-28T18:59:54.138199Z","shell.execute_reply.started":"2022-04-28T18:59:54.090833Z","shell.execute_reply":"2022-04-28T18:59:54.137633Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"annotations['labels'] = labels\nannotations.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.139189Z","iopub.execute_input":"2022-04-28T18:59:54.139551Z","iopub.status.idle":"2022-04-28T18:59:54.150447Z","shell.execute_reply.started":"2022-04-28T18:59:54.139521Z","shell.execute_reply":"2022-04-28T18:59:54.149576Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# CNN SPECTROGRAM APPROACH","metadata":{}},{"cell_type":"markdown","source":"## Data exploration","metadata":{}},{"cell_type":"code","source":"signal, sample_rate = librosa.load('../input/PMEmo2019/chorus/945.mp3', sr=22050)\nlibrosa.display.waveshow(signal, sr=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:54.152603Z","iopub.execute_input":"2022-04-28T18:59:54.153433Z","iopub.status.idle":"2022-04-28T18:59:58.352244Z","shell.execute_reply.started":"2022-04-28T18:59:54.153378Z","shell.execute_reply":"2022-04-28T18:59:58.351424Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"hop_length = 512 # in num. of samples\nn_fft = 2048 # window in num. of samples\n\n# MFCCs\n# extract 13 MFCCs\nMFCCs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n\n\nlibrosa.display.specshow(MFCCs, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"MFCC coefficients\")\nplt.colorbar()\nplt.title(\"MFCCs\")\n\n# show plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:58.353689Z","iopub.execute_input":"2022-04-28T18:59:58.354413Z","iopub.status.idle":"2022-04-28T18:59:58.662159Z","shell.execute_reply.started":"2022-04-28T18:59:58.354370Z","shell.execute_reply":"2022-04-28T18:59:58.661214Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation\nI file audio vengono caricati con una durata massima di 60 secondi. Successivamente i file pi√π corti vengono modificati per essere di 60 secondi.","metadata":{}},{"cell_type":"code","source":"SAMPLE_RATE = 22050\nTRACK_DURATION = 60\nSAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n\nnum_segments = 10\nsamples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n\n\nnum_mfcc = 13\nn_fft = 2048\nhop_length = 512\n\nnum_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n\n\ndata = {\n    'ID' : [],\n    'MFCC' : [],\n    'Label' : []\n}\n\nfor index, row in annotations.iterrows():\n    print(\"Processando canzone ID: \"+row[0])\n    \n    file_name = str(row[0]) + '.mp3'\n    file_path = os.path.join(chorus_path, file_name)\n    \n    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE, duration=TRACK_DURATION)\n    padded_audio = fix_length(signal, size=TRACK_DURATION*sample_rate) # array size is required_audio_size*sampling frequency\n    \n    for d in range(num_segments):\n\n                    # calculate start and finish sample for current segment\n                    start = samples_per_segment * d\n                    finish = start + samples_per_segment\n\n                    # extract mfcc\n                    mfcc = librosa.feature.mfcc(y=padded_audio[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n                    mfcc = mfcc.T\n\n                    # store only mfcc feature with expected number of vectors\n                    if len(mfcc) == num_mfcc_vectors_per_segment:\n                        data[\"ID\"].append(str(row[0]) +'.'+ str(d))\n                        data[\"MFCC\"].append(mfcc.tolist())\n                        data[\"Label\"].append(row[3])\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-28T18:59:58.665261Z","iopub.execute_input":"2022-04-28T18:59:58.665604Z","iopub.status.idle":"2022-04-28T19:29:14.425746Z","shell.execute_reply.started":"2022-04-28T18:59:58.665540Z","shell.execute_reply":"2022-04-28T19:29:14.424453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data)\n\n\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:29:14.431698Z","iopub.execute_input":"2022-04-28T19:29:14.435036Z","iopub.status.idle":"2022-04-28T19:29:14.814244Z","shell.execute_reply.started":"2022-04-28T19:29:14.434961Z","shell.execute_reply":"2022-04-28T19:29:14.813652Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"librosa.display.specshow(np.array(df['MFCC'][703]).T, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"MFCC coefficients\")\nplt.colorbar()\nplt.title(\"MFCCs\")\n\n# show plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:29:14.815150Z","iopub.execute_input":"2022-04-28T19:29:14.815798Z","iopub.status.idle":"2022-04-28T19:29:14.994356Z","shell.execute_reply.started":"2022-04-28T19:29:14.815761Z","shell.execute_reply":"2022-04-28T19:29:14.993669Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"librosa.display.specshow(np.array(df['MFCC'][706]).T, sr=sample_rate, hop_length=hop_length)\nplt.xlabel(\"Time\")\nplt.ylabel(\"MFCC coefficients\")\nplt.colorbar()\nplt.title(\"MFCCs\")\n\n# show plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:29:14.995335Z","iopub.execute_input":"2022-04-28T19:29:14.996377Z","iopub.status.idle":"2022-04-28T19:29:15.175366Z","shell.execute_reply.started":"2022-04-28T19:29:14.996323Z","shell.execute_reply":"2022-04-28T19:29:15.174513Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Rimuovo tutte le righe che contengono parti aggiunte tramite padding","metadata":{}},{"cell_type":"code","source":"zero = df['MFCC'][706] # lista di riferimento contenente valori aggiunti da padding\n\nfor index, row in df.iterrows():\n    if row[1] == zero:\n        df = df[df.ID != row[0]]\n        \ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:29:15.176729Z","iopub.execute_input":"2022-04-28T19:29:15.177162Z","iopub.status.idle":"2022-04-28T19:29:19.851647Z","shell.execute_reply.started":"2022-04-28T19:29:15.177125Z","shell.execute_reply":"2022-04-28T19:29:19.850613Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df.to_csv('mfcc.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:29:19.852916Z","iopub.execute_input":"2022-04-28T19:29:19.853158Z","iopub.status.idle":"2022-04-28T19:29:39.028902Z","shell.execute_reply.started":"2022-04-28T19:29:19.853130Z","shell.execute_reply":"2022-04-28T19:29:39.027936Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X = np.stack(df[\"MFCC\"])    \nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:51:02.546828Z","iopub.execute_input":"2022-04-28T19:51:02.547286Z","iopub.status.idle":"2022-04-28T19:51:04.205326Z","shell.execute_reply.started":"2022-04-28T19:51:02.547239Z","shell.execute_reply":"2022-04-28T19:51:04.204528Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"Y = np.array(df[\"Label\"])\nY.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-28T19:51:34.878955Z","iopub.execute_input":"2022-04-28T19:51:34.879234Z","iopub.status.idle":"2022-04-28T19:51:34.886995Z","shell.execute_reply.started":"2022-04-28T19:51:34.879206Z","shell.execute_reply":"2022-04-28T19:51:34.885976Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:04:22.455378Z","iopub.execute_input":"2022-04-28T21:04:22.455672Z","iopub.status.idle":"2022-04-28T21:04:22.527300Z","shell.execute_reply.started":"2022-04-28T21:04:22.455641Z","shell.execute_reply":"2022-04-28T21:04:22.526472Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"X_train = X_train[..., np.newaxis]\nX_test = X_test[..., np.newaxis]\n\n\ninput_shape = (X_train.shape[1], X_train.shape[2], 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:04:23.766871Z","iopub.execute_input":"2022-04-28T21:04:23.767313Z","iopub.status.idle":"2022-04-28T21:04:23.771822Z","shell.execute_reply.started":"2022-04-28T21:04:23.767279Z","shell.execute_reply":"2022-04-28T21:04:23.770877Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential()\n\n\n# 1st conv layer\nmodel.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(Dropout(0.2))\n\n# 2nd conv layer\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(Dropout(0.2))\n\n# 3rd conv layer\nmodel.add(keras.layers.Conv2D(128, (2, 2), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(Dropout(0.2))\n\n# 4rd conv layer\nmodel.add(keras.layers.Conv2D(256, (1,1), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\n# flatten output and feed it into dense layer\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(512, activation='relu'))\nmodel.add(keras.layers.Dropout(0.4))\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dropout(0.3))\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.Dropout(0.2))\n\n# output layer\nmodel.add(keras.layers.Dense(4, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n             loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:35:04.074693Z","iopub.execute_input":"2022-04-28T21:35:04.075487Z","iopub.status.idle":"2022-04-28T21:35:04.269416Z","shell.execute_reply.started":"2022-04-28T21:35:04.075446Z","shell.execute_reply":"2022-04-28T21:35:04.268150Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:35:07.481989Z","iopub.execute_input":"2022-04-28T21:35:07.482258Z","iopub.status.idle":"2022-04-28T21:35:07.798070Z","shell.execute_reply.started":"2022-04-28T21:35:07.482228Z","shell.execute_reply":"2022-04-28T21:35:07.797258Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"filepath_cnn=\"weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath_cnn, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\n\nhistory = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=15, callbacks=[checkpoint])\nmodel.load_weights(filepath_cnn)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:35:09.819805Z","iopub.execute_input":"2022-04-28T21:35:09.820632Z","iopub.status.idle":"2022-04-28T21:37:05.992941Z","shell.execute_reply.started":"2022-04-28T21:35:09.820556Z","shell.execute_reply":"2022-04-28T21:37:05.992019Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"x_plot = list(range(1,15 + 1))\ndef plot_history(network_history):\n    plt.figure()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.plot(x_plot, network_history.history['loss'])\n    plt.plot(x_plot, network_history.history['val_loss'])\n    plt.legend(['Training', 'Validation'])\n    plt.figure()\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.plot(x_plot, network_history.history['accuracy'])\n    plt.plot(x_plot, network_history.history['val_accuracy'])\n    plt.legend(['Training', 'Validation'], loc='lower right')\n    plt.show()\n    \nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:37:12.899427Z","iopub.execute_input":"2022-04-28T21:37:12.900366Z","iopub.status.idle":"2022-04-28T21:37:13.274803Z","shell.execute_reply.started":"2022-04-28T21:37:12.900316Z","shell.execute_reply":"2022-04-28T21:37:13.273804Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\nprint('\\nTest accuracy:', test_acc)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T21:37:16.927931Z","iopub.execute_input":"2022-04-28T21:37:16.928511Z","iopub.status.idle":"2022-04-28T21:37:17.734914Z","shell.execute_reply.started":"2022-04-28T21:37:16.928463Z","shell.execute_reply":"2022-04-28T21:37:17.733907Z"},"trusted":true},"execution_count":139,"outputs":[]}]}